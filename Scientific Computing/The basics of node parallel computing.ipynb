{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "julia-1.5",
   "display_name": "Julia 1.5.0",
   "language": "julia"
  },
  "metadata": {
   "interpreter": {
    "hash": "177b667bbd2120d0945f6a3067172dc7a8ac4c3cb077d3ec6208cb503131f1af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 20.102833 seconds (617 allocations: 18.125 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time for i in 1:10 \n",
    "sleep(2)\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  0.007297 seconds (6.23 k allocations: 370.582 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time for i in 1:10 \n",
    "     @async sleep(2)\n",
    "end "
   ]
  },
  {
   "source": [
    "Notice that by adding @async we have reduced the time. We have added threads which do the calculations parallely and hence time required is very less."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\u001b[36m  @async\u001b[39m\n",
       "\n",
       "  Wrap an expression in a \u001b[36mTask\u001b[39m and add it to the local machine's scheduler\n",
       "  queue.\n",
       "\n",
       "  Values can be interpolated into \u001b[36m@async\u001b[39m via \u001b[36m$\u001b[39m, which copies the value\n",
       "  directly into the constructed underlying closure. This allows you to insert\n",
       "  the \u001b[4mvalue\u001b[24m of a variable, isolating the aysnchronous code from changes to the\n",
       "  variable's value in the current task.\n",
       "\n",
       "\u001b[39m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[1mJulia 1.4\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  Interpolating values via \u001b[36m$\u001b[39m is available as of Julia 1.4."
      ],
      "text/markdown": "```\n@async\n```\n\nWrap an expression in a [`Task`](@ref) and add it to the local machine's scheduler queue.\n\nValues can be interpolated into `@async` via `$`, which copies the value directly into the constructed underlying closure. This allows you to insert the *value* of a variable, isolating the aysnchronous code from changes to the variable's value in the current task.\n\n!!! compat \"Julia 1.4\"\n    Interpolating values via `$` is available as of Julia 1.4.\n\n",
      "text/latex": "\\begin{verbatim}\n@async\n\\end{verbatim}\nWrap an expression in a \\href{@ref}{\\texttt{Task}} and add it to the local machine's scheduler queue.\n\nValues can be interpolated into \\texttt{@async} via \\texttt{\\$}, which copies the value directly into the constructed underlying closure. This allows you to insert the \\emph{value} of a variable, isolating the aysnchronous code from changes to the variable's value in the current task.\n\n\\begin{quote}\n\\textbf{compat}\n\nJulia 1.4\n\nInterpolating values via \\texttt{\\$} is available as of Julia 1.4.\n\n\\end{quote}\n"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "?@async"
   ]
  },
  {
   "source": [
    "# @async and @sync\n",
    "Refer  [Site](https://riptutorial.com/julia-lang/example/15919/-async-and--sync)\n",
    "* According to the documentation under ?@async, \"@async wraps an expression in a Task.\" What this means is that for whatever falls within its scope, Julia will start this task running but then proceed to whatever comes next in the script without waiting for the task to complete. Thus, for instance, without the macro you will get:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  2.009118 seconds (64 allocations: 1.984 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time sleep(2)"
   ]
  },
  {
   "source": [
    "But with the macro, you get:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  0.000066 seconds (26 allocations: 2.250 KiB)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "@time @async sleep(2)\n"
   ]
  },
  {
   "source": [
    "Julia thus allows the script to proceed (and the @time macro to fully execute) without waiting for the task (in this case, sleeping for two seconds) to complete.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The @sync macro, by contrast, will \"Wait until all dynamically-enclosed uses of @async, @spawn, @spawnat and @parallel are complete.\" (according to the documentation under ?@sync). Thus, we see:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  2.045602 seconds (1.34 k allocations: 70.828 KiB)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Task (done) @0x000000003b4a2b30"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "@time @sync @async sleep(2)"
   ]
  },
  {
   "source": [
    "In this simple example then, there is no point to including a single instance of @async and @sync together. But, where @sync can be useful is where you have @async applied to multiple operations that you wish to allow to all start at once without waiting for each to complete.\n",
    "\n",
    "For example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  0.000058 seconds (58 allocations: 8.734 KiB)\n",
      "  2.110324 seconds (1.65 k allocations: 93.312 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time @sync @time for i in 1:10\n",
    "    @async sleep(2)\n",
    "    end"
   ]
  },
  {
   "source": [
    "So 0.000058 seconds is the time required to generate the threads and so all operations now are run **parallely** and hence take ~2 seconds.\n",
    "\n",
    "Notice that the above is actually **concurrency** since there is no computation involved."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Examples of the Differences\n",
    "Synchronous = Thread will complete an action Blocking = Thread will wait until action is completed\n",
    "\n",
    "* Asynchronous + Non-Blocking: I/O\n",
    "\n",
    "* Asynchronous + Blocking: Threaded atomics (demonstrated next lecture)\n",
    "\n",
    "* Synchronous + Blocking: Standard computing, @sync\n",
    "\n",
    "* Synchronous + Non-Blocking: Webservers where an I/O operation can be performed, but one never checks if the operation is completed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Multithreading\n",
    "If your threads are independent, then it may make sense to run them in parallel. This is the form of parallelism known as multithreading. To understand the data that is available in a multithreaded setup, let's look at the picture of threads again:\n",
    "![img](https://blog-assets.risingstack.com/2017/02/kernel-processes-and-threads-1.png)\n",
    "\n",
    "\n",
    "Each thread has its own call stack, but it's the process that holds the heap. This means that dynamically-sized heap allocated objects are shared between threads with no cost, a setup known as shared-memory computing."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Loop-Based Multithreading with @threads\n",
    "Let's look back at our Lorenz dynamical system from before:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  4.700 μs (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000-element Array{SArray{Tuple{3},Float64,1,3},1}:\n",
       " [1.0, 0.0, 0.0]\n",
       " [0.8, 0.56, 0.0]\n",
       " [0.752, 0.9968000000000001, 0.008960000000000001]\n",
       " [0.80096, 1.3978492416000001, 0.023474005333333336]\n",
       " [0.92033784832, 1.8180538219817644, 0.04461448495326095]\n",
       " [1.099881043052353, 2.296260732619613, 0.07569952060880669]\n",
       " [1.339156980965805, 2.864603692722823, 0.12217448583728006]\n",
       " [1.6442463233172087, 3.5539673118971193, 0.19238159391549564]\n",
       " [2.026190521033191, 4.397339452147425, 0.2989931959555302]\n",
       " [2.5004203072560376, 5.431943011293093, 0.4612438424853632]\n",
       " [3.0867248480634486, 6.700473453723668, 0.7082869831520391]\n",
       " [3.8094745691954923, 8.25130415895562, 1.0841620354518975]\n",
       " [4.697840487147518, 10.136982080467158, 1.655002727352565]\n",
       " ⋮\n",
       " [10.49730559336705, 4.660822889495989, 35.336831929448614]\n",
       " [9.330009052592839, 3.0272670946941713, 34.430722536963344]\n",
       " [8.069460661013105, 1.766747763108672, 33.159305922954225]\n",
       " [6.8089180814322185, 0.8987564841782779, 31.6759436385101]\n",
       " [5.6268857619814305, 0.3801973723631693, 30.108951163308078]\n",
       " [4.577548084057778, 0.13525687944525802, 28.545926978224173]\n",
       " [3.6890898431352737, 0.08257160199224252, 27.035860436772758]\n",
       " [2.9677861949066675, 0.15205611935372762, 25.600040161309696]\n",
       " [2.4046401797960795, 0.2914663505185634, 24.24373008707723]\n",
       " [1.9820054139405763, 0.46628657468365653, 22.964748583050085]\n",
       " [1.6788616460891923, 0.6565587545689172, 21.758445642263496]\n",
       " [1.4744010677851374, 0.8530017039412324, 20.62004063423844]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "using StaticArrays, BenchmarkTools\n",
    "function lorenz(u,p)\n",
    "  α,σ,ρ,β = p\n",
    "  @inbounds begin\n",
    "    du1 = u[1] + α*(σ*(u[2]-u[1]))\n",
    "    du2 = u[2] + α*(u[1]*(ρ-u[3]) - u[2])\n",
    "    du3 = u[3] + α*(u[1]*u[2] - β*u[3])\n",
    "  end\n",
    "  @SVector [du1,du2,du3]\n",
    "end\n",
    "function solve_system_save!(u,f,u0,p,n)\n",
    "  @inbounds u[1] = u0\n",
    "  @inbounds for i in 1:length(u)-1\n",
    "    u[i+1] = f(u[i],p)\n",
    "  end\n",
    "  u\n",
    "end\n",
    "p = (0.02,10.0,28.0,8/3)\n",
    "u = Vector{typeof(@SVector([1.0,0.0,0.0]))}(undef,1000)\n",
    "@btime solve_system_save!(u,lorenz,@SVector([1.0,0.0,0.0]),p,1000)"
   ]
  },
  {
   "source": [
    "In order to use multithreading on this code, we need to take a look at the dependency graph and see what items can be calculated independently of each other. Notice that\n",
    "\n",
    "```math\n",
    "σ*(u[2]-u[1])\n",
    "ρ-u[3]\n",
    "u[1]*u[2]\n",
    "β*u[3]\n",
    "```\n",
    "are all independent operations, so in theory we could split those off to different threads, move up, etc.\n",
    "\n",
    "Or we can have three threads:\n",
    "\n",
    "```math \n",
    "u[1] + α*(σ*(u[2]-u[1]))\n",
    "u[2] + α*(u[1]*(ρ-u[3]) - u[2])\n",
    "u[3] + α*(u[1]*u[2] - β*u[3])\n",
    "```\n",
    "all don't depend on the output of each other, so these tasks can be run in parallel. We can do this by using Julia's Threads.@threads macro which puts each of the computations of a loop in a different thread. The threaded loops do not allow you to return a value, so how do you build up the values for the @SVector?\n",
    "\n",
    "\n",
    "It's not possible!\n",
    "\n",
    "\n",
    "There is a shared heap, but the stacks are thread local. This means that a value cannot be stack allocated in one thread and magically appear when re-entering the main thread: it needs to go on the heap somewhere. But if it needs to go onto the heap, then it makes sense for us to have preallocated its location. But if we want to preallocate $du[1], du[2], and du[3]$, then it makes sense to use the fully non-allocating update form:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  5.960 μs (1 allocation: 112 bytes)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000-element Array{Array{Float64,1},1}:\n",
       " [1.0, 0.0, 0.0]\n",
       " [0.8, 0.56, 0.0]\n",
       " [0.752, 0.9968000000000001, 0.008960000000000001]\n",
       " [0.80096, 1.3978492416000001, 0.023474005333333336]\n",
       " [0.92033784832, 1.8180538219817644, 0.04461448495326095]\n",
       " [1.099881043052353, 2.296260732619613, 0.07569952060880669]\n",
       " [1.339156980965805, 2.864603692722823, 0.12217448583728006]\n",
       " [1.6442463233172087, 3.5539673118971193, 0.19238159391549564]\n",
       " [2.026190521033191, 4.397339452147425, 0.2989931959555302]\n",
       " [2.5004203072560376, 5.431943011293093, 0.4612438424853632]\n",
       " [3.0867248480634486, 6.700473453723668, 0.7082869831520391]\n",
       " [3.8094745691954923, 8.25130415895562, 1.0841620354518975]\n",
       " [4.697840487147518, 10.136982080467158, 1.655002727352565]\n",
       " ⋮\n",
       " [10.49730559336705, 4.660822889495989, 35.336831929448614]\n",
       " [9.330009052592839, 3.0272670946941713, 34.430722536963344]\n",
       " [8.069460661013105, 1.766747763108672, 33.159305922954225]\n",
       " [6.8089180814322185, 0.8987564841782779, 31.6759436385101]\n",
       " [5.6268857619814305, 0.3801973723631693, 30.108951163308078]\n",
       " [4.577548084057778, 0.13525687944525802, 28.545926978224173]\n",
       " [3.6890898431352737, 0.08257160199224252, 27.035860436772758]\n",
       " [2.9677861949066675, 0.15205611935372762, 25.600040161309696]\n",
       " [2.4046401797960795, 0.2914663505185634, 24.24373008707723]\n",
       " [1.9820054139405763, 0.46628657468365653, 22.964748583050085]\n",
       " [1.6788616460891923, 0.6565587545689172, 21.758445642263496]\n",
       " [1.4744010677851374, 0.8530017039412324, 20.62004063423844]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "function lorenz!(du,u,p)\n",
    "  α,σ,ρ,β = p\n",
    "  @inbounds begin\n",
    "    du[1] = u[1] + α*(σ*(u[2]-u[1]))\n",
    "    du[2] = u[2] + α*(u[1]*(ρ-u[3]) - u[2])\n",
    "    du[3] = u[3] + α*(u[1]*u[2] - β*u[3])\n",
    "  end\n",
    "end\n",
    "function solve_system_save_iip!(u,f,u0,p,n)\n",
    "  @inbounds u[1] = u0\n",
    "  @inbounds for i in 1:length(u)-1\n",
    "    f(u[i+1],u[i],p)\n",
    "  end\n",
    "  u\n",
    "end\n",
    "p = (0.02,10.0,28.0,8/3)\n",
    "u = [Vector{Float64}(undef,3) for i in 1:1000]\n",
    "@btime solve_system_save_iip!(u,lorenz!,[1.0,0.0,0.0],p,1000)"
   ]
  },
  {
   "source": [
    "and now we multithread:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  1.924 ms (5995 allocations: 967.89 KiB)\n"
     ]
    }
   ],
   "source": [
    "using Base.Threads\n",
    "function lorenz_mt!(du,u,p)\n",
    "  α,σ,ρ,β = p\n",
    "  let du=du, u=u, p=p\n",
    "    Threads.@threads for i in 1:3\n",
    "      @inbounds begin\n",
    "        if i == 1\n",
    "          du[1] = u[1] + α*(σ*(u[2]-u[1]))\n",
    "        elseif i == 2\n",
    "          du[2] = u[2] + α*(u[1]*(ρ-u[3]) - u[2])\n",
    "        else\n",
    "          du[3] = u[3] + α*(u[1]*u[2] - β*u[3])\n",
    "        end\n",
    "        nothing\n",
    "      end\n",
    "    end\n",
    "  end\n",
    "  nothing\n",
    "end\n",
    "function solve_system_save_iip!(u,f,u0,p,n)\n",
    "  @inbounds u[1] = u0\n",
    "  @inbounds for i in 1:length(u)-1\n",
    "    f(u[i+1],u[i],p)\n",
    "  end\n",
    "  u\n",
    "end\n",
    "p = (0.02,10.0,28.0,8/3)\n",
    "u = [Vector{Float64}(undef,3) for i in 1:1000]\n",
    "@btime solve_system_save_iip!(u,lorenz_mt!,[1.0,0.0,0.0],p,1000);"
   ]
  },
  {
   "source": [
    "**Parallelism doesn't always make things faster**\n",
    " There are two costs associated with this code. For one, we had to go to the slower heap+mutation version, so its implementation starting point is slower. But secondly, and more importantly, the cost of spinning a new thread is non-negligable. In fact, here we can see that it even needs to make a small allocation for the new context. The total cost is on the order of It's on the order of 50ns: not huge, but something to take note of. So what we've done is taken almost free calculations and made them ~50ns by making each in a different thread, instead of just having it be one thread with one call stack.\n",
    "\n",
    "The moral of the story is that you need to make sure that there's enough work per thread in order to effectively accelerate a program with parallelism."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data-Parallel Problems\n",
    "So not every setup is amenable to parallelism. Dynamical systems are natorious for being quite difficult to parallelize because the dependency of the future time step on the previous time step is clear, meaning that one cannot easily \"parallelize through time\" (though it is possible, which we will study later).\n",
    "\n",
    "However, one common way that these systems are generally parallelized is in their inputs. The following questions allow for independent simulations:\n",
    "\n",
    "What steady state does an input u0 go to for some list/region of initial conditions?\n",
    "\n",
    "How does the solution very when I use a different p?\n",
    "\n",
    "The problem has a few descriptions. For one, it's called an embaressingly parallel problem since the problem can remain largely intact to solve the parallelism problem. To solve this, we can use the exact same solve_system_save_iip!, and just change how we are calling it. Secondly, this is called a data parallel problem, since it parallelized by splitting up the input data (here, the possible u0 or ps) and acting on them independently."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000-element Array{SArray{Tuple{3},Float64,1,3},1}:\n",
       " [6.4e-323, 5.152288944e-315, 2.27e-322]\n",
       " [5.45569341e-315, NaN, 0.0]\n",
       " [0.0, -1.022081779e-314, 7.15014174e-316]\n",
       " [0.0, 8.4e-323, 4.642775625e-315]\n",
       " [0.0, 7.1501449e-316, 0.0]\n",
       " [8.4e-323, 4.642775625e-315, 5.0e-324]\n",
       " [4.77155874e-316, 0.0, 8.4e-323]\n",
       " [4.642775625e-315, 1.0e-323, 7.15014174e-316]\n",
       " [0.0, 8.4e-323, 4.642775625e-315]\n",
       " [1.5e-323, 0.0, -5.442527131007e-312]\n",
       " [0.0, 0.0, 4.649742074e-315]\n",
       " [0.0, 0.0, 4.176818213e-315]\n",
       " [0.0, 4.201675595e-315, 7.2111091e-316]\n",
       " ⋮\n",
       " [NaN, 2.1219957905e-314, 0.0]\n",
       " [0.0, 0.0, 0.0]\n",
       " [0.0, 5.455810763e-315, 8.487983164e-314]\n",
       " [0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, NaN]\n",
       " [2.1219957905e-314, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0]\n",
       " [5.455811316e-315, 8.487983164e-314, 0.0]\n",
       " [0.0, 0.0, 0.0]\n",
       " [0.0, NaN, 2.1219957905e-314]\n",
       " [0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 5.45581187e-315]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "u = Vector{typeof(@SVector([1.0,0.0,0.0]))}(undef,1000)"
   ]
  },
  {
   "source": [
    "# Multi-Threading\n",
    "\n",
    "\n",
    "## Starting Julia with multiple threads\n",
    "\n",
    "By default, Julia starts up with a single thread of execution. This can be verified by using the\n",
    "command [`Threads.nthreads()`](@ref):\n",
    "\n",
    "```julia-repl\n",
    "julia> Threads.nthreads()\n",
    "1\n",
    "```\n",
    "\n",
    "The number of execution threads is controlled either by using the\n",
    "`-t`/`--threads` command line argument or by using the\n",
    "[`JULIA_NUM_THREADS`](@ref JULIA_NUM_THREADS) environment variable. When both are\n",
    "specified, then `-t`/`--threads` takes precedence.\n",
    "\n",
    "!!! compat \"Julia 1.5\"\n",
    "    The `-t`/`--threads` command line argument requires at least Julia 1.5.\n",
    "    In older versions you must use the environment variable instead.\n",
    "\n",
    "Lets start Julia with 4 threads:\n",
    "\n",
    "```bash\n",
    "$ julia --threads 4\n",
    "```\n",
    "\n",
    "Let's verify there are 4 threads at our disposal.\n",
    "\n",
    "```julia-repl\n",
    "julia> Threads.nthreads()\n",
    "4\n",
    "```\n",
    "\n",
    "But we are currently on the master thread. To check, we use the function [`Threads.threadid`](@ref)\n",
    "\n",
    "```julia-repl\n",
    "julia> Threads.threadid()\n",
    "1\n",
    "```\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "## The `@threads` Macro\n",
    "\n",
    "Let's work a simple example using our native threads. Let us create an array of zeros:\n",
    "\n",
    "```jldoctest\n",
    "julia> a = zeros(10)\n",
    "10-element Vector{Float64}:\n",
    " 0.0\n",
    " 0.0\n",
    " 0.0\n",
    " 0.0\n",
    " 0.0\n",
    " 0.0\n",
    " 0.0\n",
    " 0.0\n",
    " 0.0\n",
    " 0.0\n",
    "```\n",
    "\n",
    "Let us operate on this array simultaneously using 4 threads. We'll have each thread write its\n",
    "thread ID into each location.\n",
    "\n",
    "Julia supports parallel loops using the [`Threads.@threads`](@ref) macro. This macro is affixed\n",
    "in front of a `for` loop to indicate to Julia that the loop is a multi-threaded region:\n",
    "\n",
    "```julia-repl\n",
    "julia> Threads.@threads for i = 1:10\n",
    "           a[i] = Threads.threadid()\n",
    "       end\n",
    "```\n",
    "\n",
    "The iteration space is split among the threads, after which each thread writes its thread ID\n",
    "to its assigned locations:\n",
    "\n",
    "```julia-repl\n",
    "julia> a\n",
    "10-element Array{Float64,1}:\n",
    " 1.0\n",
    " 1.0\n",
    " 1.0\n",
    " 2.0\n",
    " 2.0\n",
    " 2.0\n",
    " 3.0\n",
    " 3.0\n",
    " 4.0\n",
    " 4.0\n",
    "```\n",
    "\n",
    "Note that [`Threads.@threads`](@ref) does not have an optional reduction parameter like [`@distributed`](@ref).\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  5.840 μs (3 allocations: 23.55 KiB)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3-element SArray{Tuple{3},Float64,1,3} with indices SOneTo(3):\n",
       " -0.3114996234648468\n",
       " -0.30974901748976497\n",
       " 26.02460355858298"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "using Statistics\n",
    "function compute_trajectory_mean(u0,p)\n",
    "  u = Vector{typeof(@SVector([1.0,0.0,0.0]))}(undef,1000)\n",
    "  solve_system_save!(u,lorenz,u0,p,1000);\n",
    "  mean(u)\n",
    "end\n",
    "@btime compute_trajectory_mean(@SVector([1.0,0.0,0.0]),p)"
   ]
  },
  {
   "source": [
    "We can make this faster by preallocating the cache vector u. For example, we can globalize it:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  5.716 μs (3 allocations: 112 bytes)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3-element SArray{Tuple{3},Float64,1,3} with indices SOneTo(3):\n",
       " -0.3114996234648468\n",
       " -0.30974901748976497\n",
       " 26.02460355858298"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "u = Vector{typeof(@SVector([1.0,0.0,0.0]))}(undef,1000)\n",
    "function compute_trajectory_mean2(u0,p)\n",
    "  # u is automatically captured\n",
    "  solve_system_save!(u,lorenz,u0,p,1000);\n",
    "  mean(u)\n",
    "end\n",
    "@btime compute_trajectory_mean2(@SVector([1.0,0.0,0.0]),p)"
   ]
  },
  {
   "source": [
    "But this is still allocating? The issue with this code is that u is a global, and captured globals cannot be inferred because their type can change at any time. Thus what we can do instead is capture a constant:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3-element SArray{Tuple{3},Float64,1,3} with indices SOneTo(3):\n",
       " -0.3114996234648468\n",
       " -0.30974901748976497\n",
       " 26.02460355858298"
      ]
     },
     "metadata": {},
     "execution_count": 23
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  5.516 μs (1 allocation: 32 bytes)\n"
     ]
    }
   ],
   "source": [
    "const _u_cache = Vector{typeof(@SVector([1.0,0.0,0.0]))}(undef,1000)\n",
    "function compute_trajectory_mean3(u0,p)\n",
    "  # u is automatically captured\n",
    "  solve_system_save!(_u_cache,lorenz,u0,p,1000);\n",
    "  mean(_u_cache)\n",
    "end\n",
    "@btime compute_trajectory_mean3(@SVector([1.0,0.0,0.0]),p)"
   ]
  },
  {
   "source": [
    "Now it's just allocating the output. The other way to do this is to use a closure which encapsolates the cache data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  5.667 μs (1 allocation: 32 bytes)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3-element SArray{Tuple{3},Float64,1,3} with indices SOneTo(3):\n",
       " -0.3114996234648468\n",
       " -0.30974901748976497\n",
       " 26.02460355858298"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "function _compute_trajectory_mean4(u,u0,p)\n",
    "  solve_system_save!(u,lorenz,u0,p,1000);\n",
    "  mean(u)\n",
    "end\n",
    "compute_trajectory_mean4(u0,p) = _compute_trajectory_mean4(_u_cache,u0,p)\n",
    "@btime compute_trajectory_mean4(@SVector([1.0,0.0,0.0]),p)"
   ]
  },
  {
   "source": [
    "This is the same, but a bit more explicit. Now let's create our parameter search function. Let's take a sample of parameters:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000-element Array{NTuple{4,Float64},1}:\n",
       " (0.02, 0.44123529418802043, 1.6851587809641204, 0.239660080649843)\n",
       " (0.02, 1.4539007670432236, 24.306366989092673, 0.06084003629815922)\n",
       " (0.02, 2.342060697202677, 6.294287410587492, 0.3969872706554588)\n",
       " (0.02, 7.85637985022791, 1.2384312840302396, 0.09535698102462338)\n",
       " (0.02, 2.278338963700901, 0.04666812880234872, 1.3250117194867337)\n",
       " (0.02, 6.341917254884553, 3.916239784877317, 2.4020416363006896)\n",
       " (0.02, 1.2120950017638132, 15.75021141818561, 2.0231803103046486)\n",
       " (0.02, 3.877332504082387, 1.329689384889713, 0.001606167319778843)\n",
       " (0.02, 6.58345567263966, 21.48182064680297, 0.5816402364282525)\n",
       " (0.02, 3.54592397066795, 19.90892687068405, 1.9555446213006378)\n",
       " (0.02, 5.457010216458595, 27.227377982882814, 1.986277023603229)\n",
       " (0.02, 1.5538726752633925, 7.538595664814308, 2.0818425591152563)\n",
       " (0.02, 3.7258647369503572, 5.41245585154526, 1.7688656622098287)\n",
       " ⋮\n",
       " (0.02, 9.748810821891096, 0.5311018319797558, 0.9232324429563825)\n",
       " (0.02, 7.7799908038748455, 2.8976413544243185, 0.2762828672922648)\n",
       " (0.02, 1.428556883912131, 16.97980380769107, 0.7208393333217729)\n",
       " (0.02, 1.3760028990984896, 16.103084650764877, 1.7145613004892)\n",
       " (0.02, 2.2829564913894496, 3.748932183662621, 0.9343510092929617)\n",
       " (0.02, 4.9619729122384, 10.091460646027716, 2.0485324403988567)\n",
       " (0.02, 3.6042625299187936, 1.9220815794408228, 0.8098506284889849)\n",
       " (0.02, 8.637970957520245, 8.909082179906601, 2.003011949791029)\n",
       " (0.02, 4.196889025947732, 5.0824397495800975, 1.6928767997917067)\n",
       " (0.02, 4.469116115031893, 10.830514767094755, 1.1027515378294592)\n",
       " (0.02, 5.213722741029898, 3.942873953456285, 2.2577073239940617)\n",
       " (0.02, 3.2188023845352043, 1.7352314912938942, 0.4631810597563124)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "ps = [(0.02,10.0,28.0,8/3) .* (1.0,rand(3)...) for i in 1:1000]"
   ]
  },
  {
   "source": [
    "And let's get the mean of the trajectory for each of the parameters."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000-element Array{SArray{Tuple{3},Float64,1,3},1}:\n",
       " [0.47455120703230896, 0.4082570562046704, 0.7547635359056643]\n",
       " [0.33288576370319045, 0.29341270501833583, 25.053836794944047]\n",
       " [-0.9345130840839617, -0.9829389438577304, 5.092775704167578]\n",
       " [0.18559742417319422, 0.1798584953244467, 0.2541354765002672]\n",
       " [0.023001977464101313, 0.0010561648460699123, 0.00012118356439335954]\n",
       " [2.5611856821075842, 2.5741682046451753, 2.7562618467592994]\n",
       " [5.334207907584775, 5.518302329947609, 14.259905241170204]\n",
       " [0.1446332130025358, 0.13176477904169734, 0.6087904362825064]\n",
       " [0.2887811815163382, 0.274814425567736, 20.26996712736188]\n",
       " [-0.05688544989742323, 0.05668704016694275, 15.536350180043843]\n",
       " [-0.12434591786917532, -0.0037302214036733796, 24.0773676260771]\n",
       " [3.5943963521926494, 3.680937939931901, 6.273662851118569]\n",
       " [2.7205663508773212, 2.74462694713363, 4.208600644486312]\n",
       " ⋮\n",
       " [0.010914306110518922, 0.00578551420678347, 0.0002792584024665549]\n",
       " [0.662545216373358, 0.6597086434905194, 1.7974481865046095]\n",
       " [-2.766771379911141, -2.907029480016303, 15.297500601244826]\n",
       " [4.964523594494406, 5.113074113830127, 14.53000988261824]\n",
       " [1.5764622896421072, 1.589715109315203, 2.607991849889513]\n",
       " [-3.3110902913734885, -3.3697522195032192, 8.07302909816338]\n",
       " [0.8493339801992582, 0.8474452268157098, 0.8474024914715429]\n",
       " [-3.0179216537293025, -3.0471662800157033, 7.034155628902215]\n",
       " [2.5602161238360646, 2.579625871761723, 3.890667790956435]\n",
       " [-2.7000502645665616, -2.7286817879362126, 9.492618488901028]\n",
       " [2.498032743674577, 2.5131623158197436, 2.7841502367116466]\n",
       " [0.5939809444999629, 0.5875558527342972, 0.6877097050751609]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "serial_out = map(p -> compute_trajectory_mean4(@SVector([1.0,0.0,0.0]),p),ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}